{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca66dd2",
   "metadata": {},
   "source": [
    "# Solving Regression with A Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105dc19",
   "metadata": {},
   "source": [
    "Using a simple neural network for regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11d518c",
   "metadata": {},
   "source": [
    "### Step 1: Establish the question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de296b",
   "metadata": {},
   "source": [
    "Fortunately, we have worked with this dataset before back in MC2. Scientifically, we'll ask the new question: __Can a simple neural network perform better than a linear regression model on the same evaluation metrics we used before (MSE and R_sq)?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201a323e",
   "metadata": {},
   "source": [
    "For simplicity, we will use a perceptron for the regression task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b6d01",
   "metadata": {},
   "source": [
    "### Step 2: Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc01e81",
   "metadata": {},
   "source": [
    "Make sure you update your local copy of the repository by running `git pull`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "%pip install pandas numpy matplotlib scikit-learn torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6030421",
   "metadata": {},
   "source": [
    "Notice we have installed a new package, torch, which is used for building, training, and evaluating neural networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00933458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bdace9",
   "metadata": {},
   "source": [
    "### Step 3: Read and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dedeea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset with pd.read_csv (save it in a variable called df)\n",
    "# Data is in ../data/imports-85.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values using df.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are missing values, drop them using df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the first few rows of the dataset using df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column names using df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0344ba16",
   "metadata": {},
   "source": [
    "### Step 4: Data Exploration\n",
    "\n",
    "We've already explored this dataset, so we can skip this step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63be06f",
   "metadata": {},
   "source": [
    "### Step 5: Building a Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102a6d6",
   "metadata": {},
   "source": [
    "As we reviewed in the slides, a multilayer multilayer perceptron is a simple ANN with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeaa5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model class that inherits from nn.Module\n",
    "# you don't need to change anything here\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 128),   # Input layer to hidden layer (1 feature: engine-size)\n",
    "    nn.ReLU(),           # Activation function\n",
    "    nn.Linear(128, 64),  # Hidden layer to hidden layer\n",
    "    nn.Linear(64, 1)     # Hidden layer to output layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can train our model\n",
    "# Define loss function and optimizer (you don't need to change these)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ef3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try predicting price from engine size\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "# Set feature as X and predictor as y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fee2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Split the data into training and testing sets (X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "# Do this with something like: X_train = torch.tensor(X_train, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc29c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model in batches (most of the code is already there, we'll skip the implementation details)\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(YOUR_X_TRAIN), batch_size):\n",
    "        batch_losses = []\n",
    "        # Get the batch data\n",
    "        X_batch = YOUR_X_TRAIN[i:i+batch_size]\n",
    "        y_batch = YOUR_Y_TRAIN[i:i+batch_size]\n",
    "        \n",
    "        # Forward pass\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, y_batch.view(-1, 1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_losses.append(loss.item())\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    losses.append(np.mean(batch_losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33532c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses list to see your training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffac332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval() # sets model in eval mode\n",
    "losses_test = []\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(YOUR_X_TEST)\n",
    "    test_loss = criterion(test_outputs, YOUR_Y_TEST.view(-1, 1))\n",
    "    losses_test.append(test_loss.item())\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a274275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the linear regression line\n",
    "line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "line_tensor = torch.FloatTensor(line)\n",
    "plt.scatter(YOUR_X_TRAIN, YOUR_Y_TRAIN, color='blue', label='Training Data')\n",
    "plt.scatter(YOUR_X_TEST, YOUR_Y_TEST, color='orange', label='Testing Data')\n",
    "plt.plot(line, model(line_tensor).detach().numpy(), color='red', label='Regression Line')\n",
    "plt.xlabel('Engine Size')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Linear Regression: Engine Size vs Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get R-squared value\n",
    "r_squared = r2_score(YOUR_Y_TEST.numpy(), test_outputs.numpy())\n",
    "print(f'R-squared: {r_squared:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ead77",
   "metadata": {},
   "source": [
    "#### __Check in:__ How did your MLP do? Why might it have performed better or worse than your previous linear regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05334fb6",
   "metadata": {},
   "source": [
    "#### __Optional:__ Try to train an MLP on multiple variables. Does it perform better or worse than your previous model from MC2?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
